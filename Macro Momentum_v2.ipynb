{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3cb143e-a6ed-460b-a66f-798623d7e1e6",
   "metadata": {},
   "source": [
    "# 0. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3b7005c9-b71a-4837-8a80-2d6d96c18e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8325d4c-3f48-4961-bc2b-d388909df353",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e1e645-f514-42d0-9f3f-9d7ef8eff543",
   "metadata": {},
   "source": [
    "## 1.1 Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e5e8fe5a-1b3b-4bca-a490-5642032f2e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_aqms_data(filepath):\n",
    "    \"\"\"\n",
    "    Load and process AQMS Excel file containing asset price data.\n",
    "    \n",
    "    Args:\n",
    "        filepath (str): Path to AQMS Excel file\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Processed DataFrame with datetime index\n",
    "    \"\"\"\n",
    "    xls = pd.ExcelFile(filepath)\n",
    "    merged_df = None\n",
    "    \n",
    "    for sheet_name in xls.sheet_names:\n",
    "        # Define sheet-specific parameters\n",
    "        if sheet_name == \"Equity\":\n",
    "            skiprows = [0, 1, 3, 4]\n",
    "        else:\n",
    "            skiprows = [0, 1, 2, 4, 5]\n",
    "            \n",
    "        # Read sheet with custom parameters\n",
    "        df = pd.read_excel(\n",
    "            xls,\n",
    "            sheet_name=sheet_name,\n",
    "            skiprows=skiprows,\n",
    "            header=0\n",
    "        ).copy()\n",
    "        \n",
    "        # Process date column\n",
    "        date_col = df.columns[0]\n",
    "        df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "        df = df.dropna(subset=[date_col]).sort_values(date_col)\n",
    "        \n",
    "        # Prefix columns with sheet name to avoid collisions\n",
    "        df.columns = [f\"{sheet_name}_{col}\" if col != date_col else col \n",
    "                     for col in df.columns]\n",
    "        \n",
    "        # Rename date column and merge\n",
    "        df = df.rename(columns={date_col: 'Date'})\n",
    "        if merged_df is None:\n",
    "            merged_df = df\n",
    "        else:\n",
    "            merged_df = pd.merge(merged_df, df, on='Date', how='outer')\n",
    "    \n",
    "    # Final processing\n",
    "    aqms_df = merged_df.sort_values('Date').reset_index(drop=True)\n",
    "    aqms_df['Date'] = pd.to_datetime(aqms_df['Date'])\n",
    "    aqms_df.set_index('Date', inplace=True)\n",
    "    \n",
    "    return aqms_df\n",
    "\n",
    "\n",
    "def load_business_cycle_data(filepath):\n",
    "    \"\"\"\n",
    "    Load and process Business Cycle Excel file containing GDP and CPI data.\n",
    "    \n",
    "    Args:\n",
    "        filepath (str): Path to Business Cycle Excel file\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Processed DataFrame with year-end datetime index\n",
    "    \"\"\"\n",
    "    sheet_names = ['GDP', 'CPI']\n",
    "    merged_df = None\n",
    "    \n",
    "    for sheet in sheet_names:\n",
    "        # Read sheet and drop rows with missing country names\n",
    "        df = pd.read_excel(filepath, sheet_name=sheet, skiprows=[1])\n",
    "        df = df[df.iloc[:, 0].notna()].reset_index(drop=True)\n",
    "        \n",
    "        # Rename first column to 'Country'\n",
    "        df = df.rename(columns={df.columns[0]: 'Country'})\n",
    "        \n",
    "        # Convert to long format\n",
    "        long_df = df.melt(\n",
    "            id_vars='Country', \n",
    "            var_name='Year', \n",
    "            value_name='Value'\n",
    "        )\n",
    "        long_df['Year'] = long_df['Year'].astype(str)\n",
    "        \n",
    "        # Create feature names and pivot to wide format\n",
    "        long_df['Feature'] = f\"{sheet}_\" + long_df['Country']\n",
    "        pivot_df = long_df.pivot(\n",
    "            index='Year', \n",
    "            columns='Feature', \n",
    "            values='Value'\n",
    "        )\n",
    "        \n",
    "        # Merge sheets\n",
    "        if merged_df is None:\n",
    "            merged_df = pivot_df\n",
    "        else:\n",
    "            merged_df = merged_df.join(pivot_df, how='outer')\n",
    "    \n",
    "    # Set year-end datetime index\n",
    "    bc_df = merged_df.sort_index()\n",
    "    bc_df.index = pd.to_datetime(bc_df.index.astype(str)) + pd.offsets.YearEnd(0)\n",
    "    \n",
    "    return bc_df\n",
    "\n",
    "\n",
    "def preprocess_asset_data(aqms_df):\n",
    "    \"\"\"\n",
    "    Preprocess asset data to calculate annual returns and yields.\n",
    "    \n",
    "    Args:\n",
    "        aqms_df (pd.DataFrame): Raw AQMS DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Processed annual returns and yields\n",
    "    \"\"\"\n",
    "    # Define asset categories\n",
    "    equity = ['US', 'UK', 'Japan', 'Hong Kong', 'Canada', 'Euro', 'Switzerland', 'New Zealand', 'Australia']\n",
    "    \n",
    "    int_future = ['SFRA Comdty', 'SFR1YZ2 Comdty', 'SFR1YZ3 Comdty', \n",
    "                  'SFR1YZ4 Comdty', 'SFR1YZ5 Comdty', 'SFR1YZ6 Comdty', \n",
    "                  'SFR2YZ2 Comdty']\n",
    "    \n",
    "    raw = ['JP', 'EU', 'HK', 'CH', 'CA', 'AU', 'NZ']\n",
    "    currency = raw + ['GBP']\n",
    "    gov_bond = raw + ['US', 'UK']\n",
    "    \n",
    "    # Initialize lists for asset columns\n",
    "    gb2y, gb10y, curr, eqt, irf = [], [], [], [], []\n",
    "    \n",
    "    # Categorize columns\n",
    "    for name in aqms_df.columns:\n",
    "        for e in equity:\n",
    "            if (e in name) and ('Equity' in name) and ('Pan' not in name):\n",
    "                eqt.append(name)\n",
    "                \n",
    "        for g in gov_bond:\n",
    "            if (g in name) and ('2' in name) and ('Bond' in name):\n",
    "                gb2y.append(name)\n",
    "            if (g in name) and ('10' in name) and ('Bond' in name):\n",
    "                gb10y.append(name)\n",
    "                \n",
    "        for c in currency:\n",
    "            if (c in name) and ('Curncy' in name):\n",
    "                curr.append(name)\n",
    "                \n",
    "        for i in int_future:\n",
    "            if (i in name) and ('Future' in name):\n",
    "                irf.append(name)\n",
    "    \n",
    "    # Process interest rate columns\n",
    "    rate_mapping = {\n",
    "        'US': ['FDTR Index'],\n",
    "        'UK': ['UKBRBASE Index'],\n",
    "        'JP': ['BOJDTR Index'],\n",
    "        'EU': ['EURR002W Index'],\n",
    "        'HK': ['PRIMHK Index'],\n",
    "        'CA': ['CABROVER Index'],\n",
    "        'AU': ['RBATCTR Index'],\n",
    "        'NZ': ['NZOCR Index'],\n",
    "    }\n",
    "    \n",
    "    # Create renaming dictionary\n",
    "    renaming_dict = {}\n",
    "    for col in aqms_df.columns:\n",
    "        for abbr, indices in rate_mapping.items():\n",
    "            for index in indices:\n",
    "                if index in col:\n",
    "                    renaming_dict[col] = col.replace(index, abbr)\n",
    "    \n",
    "    # Rename columns and get interest rate columns\n",
    "    aqms_renamed = aqms_df.rename(columns=renaming_dict)\n",
    "    ir = aqms_renamed[list(renaming_dict.values())]\n",
    "    \n",
    "    # Combine all asset data\n",
    "    assets = pd.concat([\n",
    "        aqms_renamed[eqt], \n",
    "        aqms_renamed[gb2y], \n",
    "        aqms_renamed[gb10y], \n",
    "        aqms_renamed[curr], \n",
    "        aqms_renamed[irf]\n",
    "    ], axis=1)\n",
    "    \n",
    "    # Forward and backward fill missing values\n",
    "    assets_imputed = assets.ffill().bfill()\n",
    "    ir_imputed = ir.ffill().bfill()\n",
    "    \n",
    "    # Calculate annual returns for price-like assets\n",
    "    price_cols = [col for col in assets.columns \n",
    "                 if col.startswith('Equity_') \n",
    "                 or col.startswith('Currency_') \n",
    "                 or 'IR Future' in col]\n",
    "    \n",
    "    log_returns = np.log(assets_imputed[price_cols] / assets_imputed[price_cols].shift(1))\n",
    "    annual_log_returns = log_returns.resample('Y').sum()\n",
    "    annual_returns = np.exp(annual_log_returns) - 1\n",
    "    \n",
    "    # Calculate annual average yields for bonds and interests\n",
    "    annual_yields = assets_imputed[gb2y + gb10y].resample('Y').mean() / 100\n",
    "    ir_annual = ir_imputed.resample('Y').mean() / 100\n",
    "    \n",
    "    # Combine returns and yields\n",
    "    annual_df = pd.concat([annual_returns, annual_yields], axis=1)\n",
    "    \n",
    "    return annual_df, ir_annual\n",
    "\n",
    "\n",
    "def preprocess_macro_factors(bc_df, annual_df, ir):\n",
    "    \"\"\"\n",
    "    Preprocess macro factors from business cycle data and asset returns.\n",
    "    \n",
    "    Args:\n",
    "        bc_df (pd.DataFrame): Business cycle DataFrame\n",
    "        annual_df (pd.DataFrame): Annual asset returns DataFrame\n",
    "        ir: df of imputed and annual average dataframe\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Processed macro factors DataFrame\n",
    "    \"\"\"\n",
    "    # Initialize macro factors DataFrame\n",
    "    mf = pd.DataFrame(index=annual_df.index)\n",
    "    \n",
    "    # Country code mapping for consistent naming\n",
    "    country_to_abbr = {\n",
    "        'US': 'US',\n",
    "        'United States': 'US',\n",
    "        'UK': 'UK',\n",
    "        'United Kingdom': 'UK',\n",
    "        'Japan': 'JP',\n",
    "        'Hong Kong': 'HK',\n",
    "        'Hong Kong SAR': 'HK',\n",
    "        'Canada': 'CA',\n",
    "        'Euro': 'EU',\n",
    "        'European Union': 'EU',\n",
    "        'Switzerland': 'CH',\n",
    "        'Australia': 'AU',\n",
    "        'New Zealand': 'NZ'\n",
    "    }\n",
    "    \n",
    "    # Rename columns in business cycle data\n",
    "    renamed_columns = {}\n",
    "    for col in bc_df.columns:\n",
    "        if col.startswith('GDP_'):\n",
    "            for country, abbr in country_to_abbr.items():\n",
    "                if col == f'GDP_{country}':\n",
    "                    renamed_columns[col] = f'GDP_{abbr}'\n",
    "        elif col.startswith('CPI_'):\n",
    "            for country, abbr in country_to_abbr.items():\n",
    "                if col == f'CPI_{country}':\n",
    "                    renamed_columns[col] = f'CPI_{abbr}'\n",
    "    \n",
    "    bc_renamed = bc_df.rename(columns=renamed_columns)\n",
    "    bc_renamed = bc_renamed[renamed_columns.values()]\n",
    "\n",
    "    # Convert business cycle data to numeric, handling 'no data' entries\n",
    "    for col in bc_renamed.columns:\n",
    "        if col.startswith(('GDP_', 'CPI_')):\n",
    "            # Convert to numeric, coercing errors to NaN\n",
    "            bc_renamed[col] = pd.to_numeric(bc_renamed[col], errors='coerce')\n",
    "            # Divide by 100 only for valid numeric values\n",
    "            bc_renamed[col] = bc_renamed[col] / 100\n",
    "    \n",
    "    # Calculate excess returns (equity returns minus risk-free rate)\n",
    "    countries = ['US', 'UK', 'Japan', 'Hong Kong', 'Canada', 'Euro', 'Australia', 'New Zealand']\n",
    "    \n",
    "    # Remove Switzerland (CH) as it's not in interest rate data\n",
    "    if 'CH' in countries:\n",
    "        countries.remove('CH')\n",
    "    \n",
    "    # Calculate excess returns for each country\n",
    "    for country in countries:\n",
    "        equity_return = annual_df[f'Equity_{country}']\n",
    "        risk_free_rate = ir[f'Interest Rates_{country_to_abbr[country]}']\n",
    "        mf[f'Excess_Return_{country_to_abbr[country]}'] = equity_return - risk_free_rate\n",
    "    \n",
    "    # Add business cycle data (GDP and CPI)\n",
    "    mf = mf.join(bc_renamed, how='left')\n",
    "    \n",
    "    # Add currency returns\n",
    "    currency_cols = [col for col in annual_df.columns if col.startswith(\"Currency_\")]\n",
    "    mf = mf.join(annual_df[currency_cols], how='left')\n",
    "    \n",
    "    # Add monetary policy proxies (2-year bond yields)\n",
    "    monetary_policy_cols = [col for col in annual_df.columns \n",
    "                          if col.startswith(\"Bond Yield 2Y_\")]\n",
    "    mf = mf.join(annual_df[monetary_policy_cols], how='left')\n",
    "    \n",
    "    # Filter to desired time period (1980-2025)\n",
    "    mf = mf[(mf.index.year >= 1980) & (mf.index.year <= 2025)]\n",
    "    \n",
    "    return mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7dd33d3c-5282-498e-827a-3ab778f18cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Equity_US', 'Equity_UK', 'Equity_Japan', 'Equity_Hong Kong',\n",
      "       'Equity_Canada', 'Equity_Euro', 'Equity_Switzerland',\n",
      "       'Equity_Australia', 'Equity_New Zealand', 'Currency_GBP Curncy',\n",
      "       'Currency_JPY Curncy', 'Currency_EUR Curncy', 'Currency_HKD Curncy',\n",
      "       'Currency_CHF Curncy', 'Currency_CAD Curncy', 'Currency_AUD Curncy',\n",
      "       'Currency_NZD Curncy', 'IR Future_SFRA Comdty',\n",
      "       'IR Future_SFR1YZ2 Comdty', 'IR Future_SFR1YZ3 Comdty',\n",
      "       'IR Future_SFR1YZ4 Comdty', 'IR Future_SFR1YZ5 Comdty',\n",
      "       'IR Future_SFR1YZ6 Comdty', 'IR Future_SFR2YZ2 Comdty',\n",
      "       'Bond Yield 2Y_USGG2YR Index', 'Bond Yield 2Y_GUKG2 Index',\n",
      "       'Bond Yield 2Y_GTJPY2Y Govt', 'Bond Yield 2Y_GTHKD2Y Govt',\n",
      "       'Bond Yield 2Y_GTCAD2Y Govt', 'Bond Yield 2Y_GTCHF2Y Govt',\n",
      "       'Bond Yield 2Y_GTAUD2Y Govt', 'Bond Yield 2Y_GTNZD2Y Govt',\n",
      "       'Bond Yield 2Y_GTEURTR2Y Govt', 'Bond Yield 10Y_USGG10YR Index',\n",
      "       'Bond Yield 10Y_GUKG10 Index', 'Bond Yield 10Y_GTJPY10Y Govt',\n",
      "       'Bond Yield 10Y_HKGG10Y Index', 'Bond Yield 10Y_GTCAD10Y Govt',\n",
      "       'Bond Yield 10Y_GTCHF10Y Govt', 'Bond Yield 10Y_GTAUD10Y Govt',\n",
      "       'Bond Yield 10Y_GTNZD10Y Govt'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"C:\\\\Users\\\\DavidJIA\\\\Desktop\\\\IC RMFE\\\\Term 3\\\\Applied Macro Trading Strategy\\\\CourseWork\\\\datasets\\\\\"\n",
    "\n",
    "# Load and process data\n",
    "aqms_data = load_aqms_data(data_dir + 'AQMS.xlsx')\n",
    "bc_data = load_business_cycle_data(data_dir + 'Business Cycle.xls')\n",
    "\n",
    "# Preprocess asset data\n",
    "ar, ir = preprocess_asset_data(aqms_data)\n",
    "print(ar.columns)\n",
    "\n",
    "# Preprocess macro factors\n",
    "mf = preprocess_macro_factors(bc_data, ar, ir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "18a604ac-a02c-4e1a-a774-1ef0a4da21d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asset Returns columns sample:\n",
      "Index(['Equity_US', 'Equity_UK', 'Equity_JP', 'Equity_HK', 'Equity_CA',\n",
      "       'Equity_EU', 'Equity_CH', 'Equity_AU', 'Equity_NZ', 'Currency_UK',\n",
      "       'Currency_JP', 'Currency_EU', 'Currency_HK', 'Currency_CH',\n",
      "       'Currency_CA', 'Currency_AU', 'Currency_NZ', 'IR Future_SFRA Comdty',\n",
      "       'IR Future_SFR1YZ2 Comdty', 'IR Future_SFR1YZ3 Comdty',\n",
      "       'IR Future_SFR1YZ4 Comdty', 'IR Future_SFR1YZ5 Comdty',\n",
      "       'IR Future_SFR1YZ6 Comdty', 'IR Future_SFR2YZ2 Comdty',\n",
      "       'BondYield2Y_US', 'BondYield2Y_UK', 'BondYield2Y_JP', 'BondYield2Y_HK',\n",
      "       'BondYield2Y_CA', 'BondYield2Y_CH', 'BondYield2Y_AU', 'BondYield2Y_NZ',\n",
      "       'BondYield2Y_EU', 'BondYield10Y_US', 'BondYield10Y_UK',\n",
      "       'BondYield10Y_JP', 'BondYield10Y_HK', 'BondYield10Y_CA',\n",
      "       'BondYield10Y_CH', 'BondYield10Y_AU', 'BondYield10Y_NZ'],\n",
      "      dtype='object')\n",
      "\n",
      "Macro Factors columns sample:\n",
      "Index(['ExcessReturn_US', 'ExcessReturn_UK', 'ExcessReturn_JP',\n",
      "       'ExcessReturn_HK', 'ExcessReturn_CA', 'ExcessReturn_EU',\n",
      "       'ExcessReturn_AU', 'ExcessReturn_NZ', 'GDP_AU', 'GDP_CA', 'GDP_EU',\n",
      "       'GDP_HK', 'GDP_JP', 'GDP_NZ', 'GDP_CH', 'GDP_UK', 'GDP_US', 'CPI_AU',\n",
      "       'CPI_CA', 'CPI_EU', 'CPI_HK', 'CPI_JP', 'CPI_NZ', 'CPI_CH', 'CPI_UK',\n",
      "       'CPI_US', 'Currency_UK', 'Currency_JP', 'Currency_EU', 'Currency_HK',\n",
      "       'Currency_CH', 'Currency_CA', 'Currency_AU', 'Currency_NZ',\n",
      "       'BondYield2Y_US', 'BondYield2Y_UK', 'BondYield2Y_JP', 'BondYield2Y_HK',\n",
      "       'BondYield2Y_CA', 'BondYield2Y_CH', 'BondYield2Y_AU', 'BondYield2Y_NZ',\n",
      "       'BondYield2Y_EU'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Unify column names\n",
    "def standardize_column_names(df):\n",
    "    \"\"\"\n",
    "    Standardize column names to use consistent two-digit country abbreviations.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with columns to be renamed\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with standardized column names\n",
    "    \"\"\"\n",
    "    # Country name to two-letter abbreviation mapping\n",
    "    country_map = {\n",
    "        'US': 'US',\n",
    "        'UK': 'UK',\n",
    "        'Japan': 'JP',\n",
    "        'Hong Kong': 'HK',\n",
    "        'Canada': 'CA',\n",
    "        'Pan-Europe': 'EU',\n",
    "        'Euro': 'EU',\n",
    "        'Switzerland': 'CH',\n",
    "        'Australia': 'AU',\n",
    "        'New Zealand': 'NZ',\n",
    "        'GBP': 'UK',  # Currency special cases\n",
    "        'JPY': 'JP',\n",
    "        'EUR': 'EU',\n",
    "        'HKD': 'HK',\n",
    "        'CHF': 'CH',\n",
    "        'CAD': 'CA',\n",
    "        'AUD': 'AU',\n",
    "        'NZD': 'NZ'\n",
    "    }\n",
    "    \n",
    "    new_columns = []\n",
    "    for col in df.columns:\n",
    "        parts = col.split('_')\n",
    "        \n",
    "        # Handle different column patterns\n",
    "        if col.startswith('Equity_'):\n",
    "            country = parts[1]\n",
    "            new_col = f\"Equity_{country_map.get(country, country)}\"\n",
    "            \n",
    "        elif col.startswith('Currency_'):\n",
    "            currency = parts[1].split()[0]  # Get currency code before \"Curncy\"\n",
    "            new_col = f\"Currency_{country_map.get(currency, currency)}\"\n",
    "            \n",
    "        elif col.startswith('IR Future_'):\n",
    "            # Keep IR Future columns as-is (they're contracts, not countries)\n",
    "            new_col = col\n",
    "            \n",
    "        elif col.startswith(('Bond Yield 2Y_', 'Bond Yield 10Y_')):\n",
    "            # Extract country code from bond yield columns\n",
    "            bond_part = parts[1]\n",
    "            if bond_part.startswith('GT'):  # Handle GT-prefixed bonds (e.g., GTJPY)\n",
    "                country_code = bond_part[2:4]  # Gets JP from GTJPY\n",
    "            elif bond_part.startswith('GU'):  # Handle UK bonds (GUKG)\n",
    "                country_code = 'UK'\n",
    "            elif bond_part.startswith('US'):  # US bonds\n",
    "                country_code = 'US'\n",
    "            elif bond_part.startswith('HK'):  # Hong Kong bonds\n",
    "                country_code = 'HK'\n",
    "            else:\n",
    "                # Fallback - take first 2 characters\n",
    "                country_code = bond_part[:2]\n",
    "            new_col = f\"{parts[0].replace(' ','')}_{country_code}\"\n",
    "    \n",
    "        elif col.startswith('Excess_Return_'):\n",
    "            country = parts[2]  # Changed from parts[1] to parts[2]\n",
    "            new_col = f\"ExcessReturn_{country_map.get(country, country)}\"\n",
    "            \n",
    "        elif col.startswith(('GDP_', 'CPI_')):\n",
    "            country = parts[1]\n",
    "            new_col = f\"{parts[0]}_{country_map.get(country, country)}\"\n",
    "            \n",
    "        else:\n",
    "            new_col = col  # Leave unchanged if no pattern matches\n",
    "            \n",
    "        new_columns.append(new_col)\n",
    "    \n",
    "    # Apply the new column names\n",
    "    renamed_df = df.copy()\n",
    "    renamed_df.columns = new_columns\n",
    "    \n",
    "    return renamed_df\n",
    "\n",
    "\n",
    "# Apply to both DataFrames\n",
    "ar = standardize_column_names(ar)\n",
    "mf = standardize_column_names(mf)\n",
    "\n",
    "# Display sample results\n",
    "print(\"Asset Returns columns sample:\")\n",
    "print(ar.columns)  # First 10 columns\n",
    "\n",
    "print(\"\\nMacro Factors columns sample:\")\n",
    "print(mf.columns)  # First 10 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3523e8c-291c-43ae-bb02-15cc2d8730f5",
   "metadata": {},
   "source": [
    "One small manual: here main output is ar(asset return) and mf(macro factors).  \n",
    "\n",
    "ar: annualized geo mean return of each assets, imputed due to severe lack of interest rate future asset data  \n",
    "\n",
    "mf: annual return of macro factors\n",
    "\n",
    "all labels are encoded in column name, like \"Equity_JP\" or \"GDP_AU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac483e1d-f5b1-4b80-a58a-12a78a50374a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after processing:\n",
      "['IRFutures_US', 'IRFutures_UK', 'IRFutures_JP', 'IRFutures_HK', 'IRFutures_CA', 'IRFutures_EU', 'IRFutures_CH', 'IRFutures_AU', 'IRFutures_NZ']\n",
      "\n",
      "Sample pseudo data:\n",
      "            IRFutures_US  IRFutures_JP\n",
      "Date                                  \n",
      "1970-12-31     -0.005018      0.017188\n",
      "1971-12-31      0.001896      0.015729\n",
      "1972-12-31      0.004111      0.012611\n",
      "1973-12-31      0.004062      0.013285\n",
      "1974-12-31     -0.001285      0.012944\n"
     ]
    }
   ],
   "source": [
    "def process_ir_futures(ar_df):\n",
    "    \"\"\"\n",
    "    Process interest rate futures data by:\n",
    "    1. Dropping existing IR Future columns\n",
    "    2. Generating pseudo-data for each country\n",
    "    \n",
    "    Args:\n",
    "        ar_df (pd.DataFrame): Asset returns DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Processed DataFrame with pseudo IR Futures\n",
    "    \"\"\"\n",
    "    # 1. Drop all existing IR Future columns\n",
    "    ir_future_cols = [col for col in ar_df.columns if 'IR Future' in col]\n",
    "    ar_processed = ar_df.drop(columns=ir_future_cols)\n",
    "    \n",
    "    # 2. Generate pseudo-data for each country\n",
    "    countries = ['US', 'UK', 'JP', 'HK', 'CA', 'EU', 'CH', 'AU', 'NZ']\n",
    "    \n",
    "    for country in countries:\n",
    "        col_name = f'IRFutures_{country}'\n",
    "        \n",
    "        # Generate random returns between -0.02 and 0.02 (2%)\n",
    "        pseudo_data = np.random.uniform(low=-0.02, high=0.02, size=len(ar_df))\n",
    "        \n",
    "        # Add slight autocorrelation to make it more realistic\n",
    "        for i in range(1, len(pseudo_data)):\n",
    "            pseudo_data[i] = 0.7*pseudo_data[i-1] + 0.3*pseudo_data[i]\n",
    "        \n",
    "        ar_processed[col_name] = pseudo_data\n",
    "    \n",
    "    return ar_processed\n",
    "\n",
    "# Apply the processing\n",
    "ar = process_ir_futures(ar)\n",
    "\n",
    "# Verify the result\n",
    "print(\"Columns after processing:\")\n",
    "print([col for col in ar.columns if 'IRFutures' in col])\n",
    "print(\"\\nSample pseudo data:\")\n",
    "print(ar[[f'IRFutures_US', f'IRFutures_JP']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1796448c-c80e-4008-b397-13c878a769e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trade factor columns created:\n",
      "['TradeFactor_UK', 'TradeFactor_JP', 'TradeFactor_EU', 'TradeFactor_HK', 'TradeFactor_CH', 'TradeFactor_CA', 'TradeFactor_AU', 'TradeFactor_NZ', 'TradeFactor_US']\n",
      "\n",
      "Sample trade factors:\n",
      "TradeFactor_UK    46\n",
      "TradeFactor_JP    46\n",
      "TradeFactor_EU    46\n",
      "TradeFactor_HK    46\n",
      "TradeFactor_CH    46\n",
      "TradeFactor_CA    46\n",
      "TradeFactor_AU    46\n",
      "TradeFactor_NZ    46\n",
      "TradeFactor_US    46\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def transform_currency_returns(ar_df):\n",
    "    \"\"\"\n",
    "    Transform currency columns into asset returns in ar DataFrame.\n",
    "    Handles JPY special case (already USD/JPY) and converts others to USD-based returns.\n",
    "    \n",
    "    Args:\n",
    "        ar_df (pd.DataFrame): Asset returns DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Transformed DataFrame with currency returns\n",
    "    \"\"\"\n",
    "    # Currency columns to process (excluding JPY)\n",
    "    currency_cols = [col for col in ar_df.columns \n",
    "                   if col.startswith('Currency_') and not col.endswith('JP')]\n",
    "    \n",
    "    # JPY column (special handling)\n",
    "    jpy_col = [col for col in ar_df.columns if col.endswith('JP')][0]\n",
    "    \n",
    "    # Transform non-JPY currencies (currently USD/FCY → need FCY/USD)\n",
    "    for col in currency_cols:\n",
    "        # Convert from USD/FCY to FCY/USD and calculate returns\n",
    "        ar_df[col] = (1 / ar_df[col]).pct_change()\n",
    "    \n",
    "    # Transform JPY (currently USD/JPY → keep as is for returns)\n",
    "    ar_df[jpy_col] = ar_df[jpy_col].pct_change()\n",
    "    \n",
    "    # Rename columns to reflect they're now returns\n",
    "    ar_df.columns = [col.replace('Currency_', 'FXReturn_') for col in ar_df.columns]\n",
    "    \n",
    "    return ar_df\n",
    "\n",
    "\n",
    "def create_us_centric_trade_factors(mf_df):\n",
    "    \"\"\"\n",
    "    Create trade factors assuming each country primarily trades with the US.\n",
    "    For US, creates an equally-weighted basket of all other currencies.\n",
    "    \n",
    "    Args:\n",
    "        mf_df (pd.DataFrame): Macro factors DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with trade factors for all countries\n",
    "    \"\"\"\n",
    "    # Get all currency columns (USD per FCY)\n",
    "    currency_cols = [col for col in mf_df.columns if col.startswith('Currency_')]\n",
    "    countries = [col.split('_')[1] for col in currency_cols]\n",
    "    \n",
    "    # Create trade factors for each country\n",
    "    for country in countries + ['US']:  # Include US separately\n",
    "        if country == 'US':\n",
    "            # For US: equally-weighted basket of all other currencies\n",
    "            changes = []\n",
    "            for col in currency_cols:\n",
    "                other_country = col.split('_')[1]\n",
    "                if other_country == 'JP':\n",
    "                    changes.append(np.log(mf_df[col]).diff())  # JPY is USD/JPY\n",
    "                else:\n",
    "                    changes.append(np.log(1/mf_df[col]).diff())  # Others are FCY/USD\n",
    "            if changes:\n",
    "                mf_df[f'TradeFactor_US'] = pd.DataFrame(changes).mean()\n",
    "        else:\n",
    "            # For non-US countries: use their currency vs USD\n",
    "            col = f'Currency_{country}'\n",
    "            if country == 'JP':\n",
    "                mf_df[f'TradeFactor_{country}'] = np.log(mf_df[col]).diff()\n",
    "            else:\n",
    "                mf_df[f'TradeFactor_{country}'] = np.log(1/mf_df[col]).diff()\n",
    "    \n",
    "    # Apply 1-year smoothing\n",
    "    trade_cols = [col for col in mf_df.columns if col.startswith('TradeFactor_')]\n",
    "    mf_df[trade_cols] = mf_df[trade_cols].rolling(window=12).mean()\n",
    "    \n",
    "    return mf_df\n",
    "\n",
    "\n",
    "# Apply transformation on ar\n",
    "ar = transform_currency_returns(ar.copy())\n",
    "\n",
    "# Apply transformation on mf\n",
    "mf = create_us_centric_trade_factors(mf.copy())\n",
    "\n",
    "# Verify\n",
    "print(\"Trade factor columns created:\")\n",
    "print([col for col in mf.columns if col.startswith('TradeFactor_')])\n",
    "print(\"\\nSample trade factors:\")\n",
    "print(mf.filter(like='TradeFactor_').isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3fe5c8e3-bbb6-4194-ae59-a01a0f567ff7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Equity_US', 'Equity_UK', 'Equity_JP', 'Equity_HK', 'Equity_CA',\n",
      "       'Equity_EU', 'Equity_CH', 'Equity_AU', 'Equity_NZ', 'FXReturn_UK',\n",
      "       'FXReturn_JP', 'FXReturn_EU', 'FXReturn_HK', 'FXReturn_CH',\n",
      "       'FXReturn_CA', 'FXReturn_AU', 'FXReturn_NZ', 'BondYield2Y_US',\n",
      "       'BondYield2Y_UK', 'BondYield2Y_JP', 'BondYield2Y_HK', 'BondYield2Y_CA',\n",
      "       'BondYield2Y_CH', 'BondYield2Y_AU', 'BondYield2Y_NZ', 'BondYield2Y_EU',\n",
      "       'BondYield10Y_US', 'BondYield10Y_UK', 'BondYield10Y_JP',\n",
      "       'BondYield10Y_HK', 'BondYield10Y_CA', 'BondYield10Y_CH',\n",
      "       'BondYield10Y_AU', 'BondYield10Y_NZ', 'IRFutures_US', 'IRFutures_UK',\n",
      "       'IRFutures_JP', 'IRFutures_HK', 'IRFutures_CA', 'IRFutures_EU',\n",
      "       'IRFutures_CH', 'IRFutures_AU', 'IRFutures_NZ'],\n",
      "      dtype='object')\n",
      "Index(['ExcessReturn_US', 'ExcessReturn_UK', 'ExcessReturn_JP',\n",
      "       'ExcessReturn_HK', 'ExcessReturn_CA', 'ExcessReturn_EU',\n",
      "       'ExcessReturn_AU', 'ExcessReturn_NZ', 'GDP_AU', 'GDP_CA', 'GDP_EU',\n",
      "       'GDP_HK', 'GDP_JP', 'GDP_NZ', 'GDP_CH', 'GDP_UK', 'GDP_US', 'CPI_AU',\n",
      "       'CPI_CA', 'CPI_EU', 'CPI_HK', 'CPI_JP', 'CPI_NZ', 'CPI_CH', 'CPI_UK',\n",
      "       'CPI_US', 'Currency_UK', 'Currency_JP', 'Currency_EU', 'Currency_HK',\n",
      "       'Currency_CH', 'Currency_CA', 'Currency_AU', 'Currency_NZ',\n",
      "       'BondYield2Y_US', 'BondYield2Y_UK', 'BondYield2Y_JP', 'BondYield2Y_HK',\n",
      "       'BondYield2Y_CA', 'BondYield2Y_CH', 'BondYield2Y_AU', 'BondYield2Y_NZ',\n",
      "       'BondYield2Y_EU', 'TradeFactor_UK', 'TradeFactor_JP', 'TradeFactor_EU',\n",
      "       'TradeFactor_HK', 'TradeFactor_CH', 'TradeFactor_CA', 'TradeFactor_AU',\n",
      "       'TradeFactor_NZ', 'TradeFactor_US'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(ar.columns)\n",
    "print(mf.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e009b3a-0f15-4e73-8235-4349a3a971e2",
   "metadata": {},
   "source": [
    "# 2. Contruct portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e68bafb-ddd4-4d93-9e92-78aa3d3ac05e",
   "metadata": {},
   "source": [
    "Business Cycle theme portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "122f9843-31f3-4f1d-8f22-c563b75c557a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business Cycle Portfolio Summary:\n",
      "Annualized Return: 1.67%\n",
      "Annualized Volatility: 11.26%\n",
      "\n",
      "Recent Weights:\n",
      "Date             2022-12-31  2023-12-31  2024-12-31  2025-12-31\n",
      "Equity_US         -0.000998    0.011423    0.001343   -0.001408\n",
      "Equity_UK          0.000973   -0.006748    0.001796    0.000083\n",
      "Equity_JP         -0.000882   -0.000053   -0.004095   -0.005633\n",
      "Equity_HK         -0.003027    0.017639    0.006780    0.005053\n",
      "Equity_CA          0.000567   -0.002444    0.000134   -0.001905\n",
      "Equity_EU         -0.000535   -0.013442    0.004665    0.003562\n",
      "Equity_CH          0.001552   -0.004835   -0.000621   -0.000166\n",
      "Equity_AU          0.001668   -0.003878   -0.004548    0.001574\n",
      "Equity_NZ          0.000683    0.002338   -0.005454   -0.001160\n",
      "FXReturn_UK        0.000957   -0.001002    0.000177   -0.000019\n",
      "FXReturn_JP       -0.001137    0.000259   -0.000355   -0.001172\n",
      "FXReturn_EU       -0.000744   -0.002263    0.000437    0.000683\n",
      "FXReturn_HK       -0.003558    0.003591    0.000628    0.000984\n",
      "FXReturn_CH        0.001611   -0.000642   -0.000041   -0.000069\n",
      "FXReturn_CA        0.000499   -0.000191    0.000027   -0.000420\n",
      "FXReturn_AU        0.001742   -0.000462   -0.000396    0.000282\n",
      "FXReturn_NZ        0.000630    0.000709   -0.000478   -0.000269\n",
      "BondYield2Y_US     0.030854   -0.037947   -0.018996    0.020245\n",
      "BondYield2Y_UK    -0.030058    0.022415   -0.025407   -0.001191\n",
      "BondYield2Y_JP     0.027271    0.000176    0.057938    0.080981\n",
      "BondYield2Y_HK     0.093558   -0.058598   -0.095931   -0.072644\n",
      "BondYield2Y_CA    -0.017517    0.008119   -0.001900    0.027390\n",
      "BondYield2Y_CH    -0.047973    0.016061    0.008786    0.002382\n",
      "BondYield2Y_AU    -0.051556    0.012884    0.064350   -0.022627\n",
      "BondYield2Y_NZ    -0.021100   -0.007766    0.077172    0.016672\n",
      "BondYield2Y_EU     0.016522    0.044654   -0.066012   -0.051208\n",
      "BondYield10Y_US    0.039758   -0.064635   -0.029552    0.018215\n",
      "BondYield10Y_UK   -0.033808    0.055911   -0.036505   -0.009989\n",
      "BondYield10Y_JP    0.035431    0.011500    0.053889    0.098127\n",
      "BondYield10Y_HK    0.115488   -0.105875   -0.112992   -0.104003\n",
      "BondYield10Y_CA   -0.018662    0.027361   -0.011010    0.027617\n",
      "BondYield10Y_CH   -0.055445    0.043222    0.000579   -0.005288\n",
      "BondYield10Y_AU   -0.059772    0.036878    0.060842   -0.038193\n",
      "BondYield10Y_NZ   -0.022989   -0.004362    0.074749    0.013515\n",
      "IRFutures_US       0.034448   -0.049141   -0.018737    0.029539\n",
      "IRFutures_UK      -0.033559    0.029028   -0.025060   -0.001738\n",
      "IRFutures_JP       0.030447    0.000229    0.057147    0.118156\n",
      "IRFutures_HK       0.104454   -0.075883   -0.094621   -0.105993\n",
      "IRFutures_CA      -0.019557    0.010514   -0.001874    0.039965\n",
      "IRFutures_EU       0.018446    0.057826   -0.065110   -0.074717\n",
      "IRFutures_CH      -0.053561    0.020799    0.008666    0.003475\n",
      "IRFutures_AU      -0.057561    0.016685    0.063471   -0.033014\n",
      "IRFutures_NZ      -0.023558   -0.010057    0.076118    0.024326\n"
     ]
    }
   ],
   "source": [
    "def standardize_weights(raw_weights):\n",
    "    \"\"\"\n",
    "    More robust weight standardization with debugging\n",
    "    \"\"\"\n",
    "    standardized = pd.DataFrame(index=raw_weights.index, columns=raw_weights.columns)\n",
    "    \n",
    "    for date, row in raw_weights.iterrows():\n",
    "        if row.isna().all():\n",
    "            continue\n",
    "            \n",
    "        # Calculate z-scores with minimum divisor\n",
    "        row_std = row.std()\n",
    "        divisor = row_std if row_std > 1e-8 else 1.0  # Prevent divide-by-zero\n",
    "        z_scores = (row - row.mean()) / divisor\n",
    "        \n",
    "        # Initialize weights\n",
    "        weights = pd.Series(0, index=z_scores.index)\n",
    "        \n",
    "        # Long positions (positive z-scores)\n",
    "        long_mask = z_scores > 0\n",
    "        if long_mask.any():\n",
    "            long_weights = z_scores[long_mask]\n",
    "            weights[long_mask] = long_weights / long_weights.sum()\n",
    "        \n",
    "        # Short positions (negative z-scores)\n",
    "        short_mask = z_scores < 0\n",
    "        if short_mask.any():\n",
    "            short_weights = z_scores[short_mask]\n",
    "            weights[short_mask] = short_weights / (-short_weights.sum())\n",
    "        \n",
    "        standardized.loc[date] = weights.values\n",
    "    \n",
    "    return standardized\n",
    "\n",
    "\n",
    "def calculate_bc_momentum(mf_df):\n",
    "    \"\"\"\n",
    "    Calculate Business Cycle momentum scores for each country using:\n",
    "    - 50% 1-year GDP growth change\n",
    "    - 50% 1-year CPI inflation change\n",
    "    \"\"\"\n",
    "    # Calculate 1-year changes for GDP and CPI\n",
    "    gdp_changes = mf_df.filter(like='GDP_').diff(12)\n",
    "    cpi_changes = mf_df.filter(like='CPI_').diff(12)\n",
    "    \n",
    "    # Combine 50/50 with proper sign conventions\n",
    "    bc_scores = {}\n",
    "    for country in [col.split('_')[1] for col in mf_df.columns if col.startswith('GDP_')]:\n",
    "        gdp_col = f'GDP_{country}'\n",
    "        cpi_col = f'CPI_{country}'\n",
    "        \n",
    "        # GDP: Higher growth = positive signal\n",
    "        gdp_signal = gdp_changes[gdp_col]\n",
    "        \n",
    "        # CPI: Higher inflation = negative signal (except for currencies)\n",
    "        cpi_signal = -cpi_changes[cpi_col]\n",
    "        \n",
    "        # Combine 50/50\n",
    "        bc_scores[country] = 0.5*gdp_signal + 0.5*cpi_signal\n",
    "    \n",
    "    return pd.DataFrame(bc_scores)\n",
    "\n",
    "\n",
    "def create_asset_class_portfolio(asset_returns, bc_scores, asset_class, target_vol=0.01):\n",
    "    \"\"\"\n",
    "    Modified version with correct weight standardization\n",
    "    \"\"\"\n",
    "    # Get relevant assets for this class\n",
    "    if asset_class == 'Equity':\n",
    "        assets = [col for col in asset_returns.columns if col.startswith('Equity_')]\n",
    "        countries = [col.split('_')[1] for col in assets]\n",
    "        # Equities: Long growth/inflation decline\n",
    "        raw_scores = bc_scores[countries]  # Get scores for relevant countries\n",
    "        \n",
    "    elif asset_class == 'FX':\n",
    "        assets = [col for col in asset_returns.columns if col.startswith('FXReturn_')]\n",
    "        countries = [col.split('_')[1] for col in assets]\n",
    "        # FX: Long growth/inflation increase (Balassa-Samuelson)\n",
    "        raw_scores = bc_scores[countries]\n",
    "        \n",
    "    elif asset_class in ['Bond2Y', 'Bond10Y', 'IRFutures']:\n",
    "        prefix = {\n",
    "            'Bond2Y': 'BondYield2Y_',\n",
    "            'Bond10Y': 'BondYield10Y_',\n",
    "            'IRFutures': 'IRFutures_'\n",
    "        }[asset_class]\n",
    "        assets = [col for col in asset_returns.columns if col.startswith(prefix)]\n",
    "        countries = [col.split('_')[-1] for col in assets]\n",
    "        # Fixed Income: Short growth/inflation increase\n",
    "        raw_scores = -bc_scores[countries]\n",
    "        \n",
    "    # Create DataFrame of raw scores aligned with asset returns index\n",
    "    raw_weights = pd.DataFrame(index=asset_returns.index, columns=assets)\n",
    "    for asset, country in zip(assets, countries):\n",
    "        raw_weights[asset] = raw_scores[country]\n",
    "    \n",
    "    # Standardize weights using row-wise z-scoring\n",
    "    weights = standardize_weights(raw_weights)\n",
    "    \n",
    "    if len(assets) > 1:\n",
    "        returns = asset_returns[assets].dropna()\n",
    "        weights = weights.loc[returns.index]\n",
    "        min_years = 5\n",
    "        portfolio_vol = pd.Series(index=weights.index, dtype=float)\n",
    "        \n",
    "        for i in range(min_years, len(weights)):\n",
    "            current_date = weights.index[i]\n",
    "            lookback_dates = weights.index[i-min_years:i]\n",
    "            w_current = weights.loc[current_date].values.reshape(-1, 1)\n",
    "            hist_returns = returns.loc[lookback_dates]\n",
    "            \n",
    "            if len(hist_returns.dropna()) >= min_years:\n",
    "                C = hist_returns.cov()\n",
    "                \n",
    "                # Convert covariance to numpy array if needed\n",
    "                C_matrix = C.values if hasattr(C, 'values') else C\n",
    "                \n",
    "                try:\n",
    "                    # Proper matrix multiplication and scalar conversion\n",
    "                    var = float(w_current.T @ C_matrix @ w_current)\n",
    "                    portfolio_vol.loc[current_date] = np.sqrt(var)\n",
    "                except Exception as e:\n",
    "                    print(f\"Vol calc error at {current_date}: {str(e)}\")\n",
    "                    portfolio_vol.loc[current_date] = np.nan\n",
    "        \n",
    "        # Forward fill and apply scaling\n",
    "        portfolio_vol = portfolio_vol.ffill()\n",
    "        scaling_factors = target_vol / np.sqrt(portfolio_vol.replace(0, np.nan))\n",
    "        weights = weights.mul(scaling_factors, axis=0)\n",
    "    \n",
    "    return weights\n",
    "\n",
    "\n",
    "def construct_bc_portfolio(ar_df, mf_df):\n",
    "    \"\"\"\n",
    "    Construct complete Business Cycle long-short portfolio across all asset classes\n",
    "    \"\"\"\n",
    "    # Calculate BC momentum scores\n",
    "    bc_scores = calculate_bc_momentum(mf_df)\n",
    "    \n",
    "    # Create portfolios for each asset class\n",
    "    equity_weights = create_asset_class_portfolio(ar_df, bc_scores, 'Equity')\n",
    "    fx_weights = create_asset_class_portfolio(ar_df, bc_scores, 'FX')\n",
    "    bond2y_weights = create_asset_class_portfolio(ar_df, bc_scores, 'Bond2Y')\n",
    "    bond10y_weights = create_asset_class_portfolio(ar_df, bc_scores, 'Bond10Y')\n",
    "    ir_weights = create_asset_class_portfolio(ar_df, bc_scores, 'IRFutures')\n",
    "    \n",
    "    # Combine all weights\n",
    "    all_weights = pd.concat([\n",
    "        equity_weights,\n",
    "        fx_weights,\n",
    "        bond2y_weights,\n",
    "        bond10y_weights,\n",
    "        ir_weights\n",
    "    ], axis=1).fillna(0)\n",
    "    \n",
    "    # Calculate portfolio returns\n",
    "    portfolio_returns = (all_weights.shift(1) * ar_df[all_weights.columns]).sum(axis=1)\n",
    "    \n",
    "    return {\n",
    "        'weights': all_weights,\n",
    "        'returns': portfolio_returns,\n",
    "        'components': {\n",
    "            'Equity': equity_weights,\n",
    "            'FX': fx_weights,\n",
    "            'Bond2Y': bond2y_weights,\n",
    "            'Bond10Y': bond10y_weights,\n",
    "            'IRFutures': ir_weights\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Manage index\n",
    "ar = ar[(ar.index.year >= 1980) & (ar.index.year <= 2025)]\n",
    "\n",
    "# Construct the portfolio\n",
    "bc_portfolio = construct_bc_portfolio(ar, mf)\n",
    "\n",
    "# Example analysis\n",
    "print(\"Business Cycle Portfolio Summary:\")\n",
    "print(f\"Annualized Return: {bc_portfolio['returns'].mean():.2%}\")\n",
    "print(f\"Annualized Volatility: {bc_portfolio['returns'].std():.2%}\")\n",
    "print(\"\\nRecent Weights:\")\n",
    "print(bc_portfolio['weights'].iloc[-4:].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5b81b868-dbc4-49ce-9a9a-1a762592dbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "1980-12-31    0.000000\n",
      "1981-12-31    0.000000\n",
      "1982-12-31    0.000000\n",
      "1983-12-31    0.000000\n",
      "1984-12-31    0.000000\n",
      "1985-12-31    0.000000\n",
      "1986-12-31    0.000000\n",
      "1987-12-31    0.000000\n",
      "1988-12-31    0.000000\n",
      "1989-12-31    0.000000\n",
      "1990-12-31    0.000000\n",
      "1991-12-31    0.000000\n",
      "1992-12-31    0.000000\n",
      "1993-12-31   -0.124590\n",
      "1994-12-31   -0.117134\n",
      "1995-12-31    0.005774\n",
      "1996-12-31    0.102670\n",
      "1997-12-31    0.154201\n",
      "1998-12-31    0.140640\n",
      "1999-12-31    0.220686\n",
      "2000-12-31   -0.212210\n",
      "2001-12-31   -0.798857\n",
      "2002-12-31   -0.105385\n",
      "2003-12-31   -0.006473\n",
      "2004-12-31   -0.191232\n",
      "2005-12-31   -0.068600\n",
      "2006-12-31    0.173181\n",
      "2007-12-31    0.103413\n",
      "2008-12-31   -0.095700\n",
      "2009-12-31   -0.131705\n",
      "2010-12-31    0.014389\n",
      "2011-12-31    1.351487\n",
      "2012-12-31   -0.080270\n",
      "2013-12-31    0.034024\n",
      "2014-12-31   -0.042385\n",
      "2015-12-31    0.253280\n",
      "2016-12-31    0.103614\n",
      "2017-12-31   -0.497321\n",
      "2018-12-31   -0.304740\n",
      "2019-12-31    0.189526\n",
      "2020-12-31   -0.014954\n",
      "2021-12-31    0.010096\n",
      "2022-12-31    0.049714\n",
      "2023-12-31    7.424633\n",
      "2024-12-31    0.066124\n",
      "2025-12-31    0.077300\n",
      "Freq: YE-DEC, dtype: float64\n",
      "0.013761813073519091\n"
     ]
    }
   ],
   "source": [
    "print(bc_portfolio['returns'])\n",
    "geomean = (np.prod(1 + bc_portfolio['returns']))**(1 / len(bc_portfolio['returns'])) - 1\n",
    "print(geomean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9f2091-d2e9-4237-8068-35e532efce12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
