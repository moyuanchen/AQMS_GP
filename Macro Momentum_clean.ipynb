{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3cb143e-a6ed-460b-a66f-798623d7e1e6",
   "metadata": {},
   "source": [
    "# 0. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b7005c9-b71a-4837-8a80-2d6d96c18e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8325d4c-3f48-4961-bc2b-d388909df353",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e1e645-f514-42d0-9f3f-9d7ef8eff543",
   "metadata": {},
   "source": [
    "## 1.1 Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5e8fe5a-1b3b-4bca-a490-5642032f2e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_aqms_data(filepath):\n",
    "    \"\"\"\n",
    "    Load and process AQMS Excel file containing asset price data.\n",
    "    \n",
    "    Args:\n",
    "        filepath (str): Path to AQMS Excel file\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Processed DataFrame with datetime index\n",
    "    \"\"\"\n",
    "    xls = pd.ExcelFile(filepath)\n",
    "    merged_df = None\n",
    "    \n",
    "    for sheet_name in xls.sheet_names:\n",
    "        # Define sheet-specific parameters\n",
    "        if sheet_name == \"Equity\":\n",
    "            skiprows = [0, 1, 3, 4]\n",
    "        else:\n",
    "            skiprows = [0, 1, 2, 4, 5]\n",
    "            \n",
    "        # Read sheet with custom parameters\n",
    "        df = pd.read_excel(\n",
    "            xls,\n",
    "            sheet_name=sheet_name,\n",
    "            skiprows=skiprows,\n",
    "            header=0\n",
    "        ).copy()\n",
    "        \n",
    "        # Process date column\n",
    "        date_col = df.columns[0]\n",
    "        df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "        df = df.dropna(subset=[date_col]).sort_values(date_col)\n",
    "        \n",
    "        # Prefix columns with sheet name to avoid collisions\n",
    "        df.columns = [f\"{sheet_name}_{col}\" if col != date_col else col \n",
    "                     for col in df.columns]\n",
    "        \n",
    "        # Rename date column and merge\n",
    "        df = df.rename(columns={date_col: 'Date'})\n",
    "        if merged_df is None:\n",
    "            merged_df = df\n",
    "        else:\n",
    "            merged_df = pd.merge(merged_df, df, on='Date', how='outer')\n",
    "    \n",
    "    # Final processing\n",
    "    aqms_df = merged_df.sort_values('Date').reset_index(drop=True)\n",
    "    aqms_df['Date'] = pd.to_datetime(aqms_df['Date'])\n",
    "    aqms_df.set_index('Date', inplace=True)\n",
    "    \n",
    "    return aqms_df\n",
    "\n",
    "\n",
    "def load_business_cycle_data(filepath):\n",
    "    \"\"\"\n",
    "    Load and process Business Cycle Excel file containing GDP and CPI data.\n",
    "    \n",
    "    Args:\n",
    "        filepath (str): Path to Business Cycle Excel file\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Processed DataFrame with year-end datetime index\n",
    "    \"\"\"\n",
    "    sheet_names = ['GDP', 'CPI']\n",
    "    merged_df = None\n",
    "    \n",
    "    for sheet in sheet_names:\n",
    "        # Read sheet and drop rows with missing country names\n",
    "        df = pd.read_excel(filepath, sheet_name=sheet, skiprows=[1])\n",
    "        df = df[df.iloc[:, 0].notna()].reset_index(drop=True)\n",
    "        \n",
    "        # Rename first column to 'Country'\n",
    "        df = df.rename(columns={df.columns[0]: 'Country'})\n",
    "        \n",
    "        # Convert to long format\n",
    "        long_df = df.melt(\n",
    "            id_vars='Country', \n",
    "            var_name='Year', \n",
    "            value_name='Value'\n",
    "        )\n",
    "        long_df['Year'] = long_df['Year'].astype(str)\n",
    "        \n",
    "        # Create feature names and pivot to wide format\n",
    "        long_df['Feature'] = f\"{sheet}_\" + long_df['Country']\n",
    "        pivot_df = long_df.pivot(\n",
    "            index='Year', \n",
    "            columns='Feature', \n",
    "            values='Value'\n",
    "        )\n",
    "        \n",
    "        # Merge sheets\n",
    "        if merged_df is None:\n",
    "            merged_df = pivot_df\n",
    "        else:\n",
    "            merged_df = merged_df.join(pivot_df, how='outer')\n",
    "    \n",
    "    # Set year-end datetime index\n",
    "    bc_df = merged_df.sort_index()\n",
    "    bc_df.index = pd.to_datetime(bc_df.index.astype(str)) + pd.offsets.YearEnd(0)\n",
    "    \n",
    "    return bc_df\n",
    "\n",
    "\n",
    "def preprocess_asset_data(aqms_df):\n",
    "    \"\"\"\n",
    "    Preprocess asset data to calculate annual returns and yields.\n",
    "    \n",
    "    Args:\n",
    "        aqms_df (pd.DataFrame): Raw AQMS DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Processed annual returns and yields\n",
    "    \"\"\"\n",
    "    # Define asset categories\n",
    "    equity = ['US', 'UK', 'Japan', 'Hong Kong', 'Canada', 'Euro', 'Switzerland', 'New Zealand', 'Australia']\n",
    "    \n",
    "    int_future = ['SFRA Comdty', 'SFR1YZ2 Comdty', 'SFR1YZ3 Comdty', \n",
    "                  'SFR1YZ4 Comdty', 'SFR1YZ5 Comdty', 'SFR1YZ6 Comdty', \n",
    "                  'SFR2YZ2 Comdty']\n",
    "    \n",
    "    raw = ['JP', 'EU', 'HK', 'CH', 'CA', 'AU', 'NZ']\n",
    "    currency = raw + ['GBP']\n",
    "    gov_bond = raw + ['US', 'UK']\n",
    "    \n",
    "    # Initialize lists for asset columns\n",
    "    gb2y, gb10y, curr, eqt, irf = [], [], [], [], []\n",
    "    \n",
    "    # Categorize columns\n",
    "    for name in aqms_df.columns:\n",
    "        for e in equity:\n",
    "            if (e in name) and ('Equity' in name) and ('Pan' not in name):\n",
    "                eqt.append(name)\n",
    "                \n",
    "        for g in gov_bond:\n",
    "            if (g in name) and ('2' in name) and ('Bond' in name):\n",
    "                gb2y.append(name)\n",
    "            if (g in name) and ('10' in name) and ('Bond' in name):\n",
    "                gb10y.append(name)\n",
    "                \n",
    "        for c in currency:\n",
    "            if (c in name) and ('Curncy' in name):\n",
    "                curr.append(name)\n",
    "                \n",
    "        for i in int_future:\n",
    "            if (i in name) and ('Future' in name):\n",
    "                irf.append(name)\n",
    "    \n",
    "    # Process interest rate columns\n",
    "    rate_mapping = {\n",
    "        'US': ['FDTR Index'],\n",
    "        'UK': ['UKBRBASE Index'],\n",
    "        'JP': ['BOJDTR Index'],\n",
    "        'EU': ['EURR002W Index'],\n",
    "        'HK': ['PRIMHK Index'],\n",
    "        'CA': ['CABROVER Index'],\n",
    "        'AU': ['RBATCTR Index'],\n",
    "        'NZ': ['NZOCR Index'],\n",
    "    }\n",
    "    \n",
    "    # Create renaming dictionary\n",
    "    renaming_dict = {}\n",
    "    for col in aqms_df.columns:\n",
    "        for abbr, indices in rate_mapping.items():\n",
    "            for index in indices:\n",
    "                if index in col:\n",
    "                    renaming_dict[col] = col.replace(index, abbr)\n",
    "    \n",
    "    # Rename columns and get interest rate columns\n",
    "    aqms_renamed = aqms_df.rename(columns=renaming_dict)\n",
    "    ir = aqms_renamed[list(renaming_dict.values())]\n",
    "    \n",
    "    # Combine all asset data\n",
    "    assets = pd.concat([\n",
    "        aqms_renamed[eqt], \n",
    "        aqms_renamed[gb2y], \n",
    "        aqms_renamed[gb10y], \n",
    "        aqms_renamed[curr], \n",
    "        aqms_renamed[irf]\n",
    "    ], axis=1)\n",
    "    \n",
    "    # Forward and backward fill missing values\n",
    "    assets_imputed = assets.ffill().bfill()\n",
    "    ir_imputed = ir.ffill().bfill()\n",
    "    \n",
    "    # Calculate annual returns for price-like assets\n",
    "    price_cols = [col for col in assets.columns \n",
    "                 if col.startswith('Equity_') \n",
    "                 or col.startswith('Currency_') \n",
    "                 or 'IR Future' in col]\n",
    "    \n",
    "    log_returns = np.log(assets_imputed[price_cols] / assets_imputed[price_cols].shift(1))\n",
    "    annual_log_returns = log_returns.resample('Y').sum()\n",
    "    annual_returns = np.exp(annual_log_returns) - 1\n",
    "    \n",
    "    # Calculate annual average yields for bonds and interests\n",
    "    annual_yields = assets_imputed[gb2y + gb10y].resample('Y').mean() / 100\n",
    "    ir_annual = ir_imputed.resample('Y').mean() / 100\n",
    "    \n",
    "    # Combine returns and yields\n",
    "    annual_df = pd.concat([annual_returns, annual_yields], axis=1)\n",
    "    \n",
    "    return annual_df, ir_annual\n",
    "\n",
    "\n",
    "def preprocess_macro_factors(bc_df, annual_df, ir):\n",
    "    \"\"\"\n",
    "    Preprocess macro factors from business cycle data and asset returns.\n",
    "    \n",
    "    Args:\n",
    "        bc_df (pd.DataFrame): Business cycle DataFrame\n",
    "        annual_df (pd.DataFrame): Annual asset returns DataFrame\n",
    "        ir: df of imputed and annual average dataframe\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Processed macro factors DataFrame\n",
    "    \"\"\"\n",
    "    # Initialize macro factors DataFrame\n",
    "    mf = pd.DataFrame(index=annual_df.index)\n",
    "    \n",
    "    # Country code mapping for consistent naming\n",
    "    country_to_abbr = {\n",
    "        'US': 'US',\n",
    "        'United States': 'US',\n",
    "        'UK': 'UK',\n",
    "        'United Kingdom': 'UK',\n",
    "        'Japan': 'JP',\n",
    "        'Hong Kong': 'HK',\n",
    "        'Hong Kong SAR': 'HK',\n",
    "        'Canada': 'CA',\n",
    "        'Euro': 'EU',\n",
    "        'European Union': 'EU',\n",
    "        'Switzerland': 'CH',\n",
    "        'Australia': 'AU',\n",
    "        'New Zealand': 'NZ'\n",
    "    }\n",
    "    \n",
    "    # Rename columns in business cycle data\n",
    "    renamed_columns = {}\n",
    "    for col in bc_df.columns:\n",
    "        if col.startswith('GDP_'):\n",
    "            for country, abbr in country_to_abbr.items():\n",
    "                if col == f'GDP_{country}':\n",
    "                    renamed_columns[col] = f'GDP_{abbr}'\n",
    "        elif col.startswith('CPI_'):\n",
    "            for country, abbr in country_to_abbr.items():\n",
    "                if col == f'CPI_{country}':\n",
    "                    renamed_columns[col] = f'CPI_{abbr}'\n",
    "    \n",
    "    bc_renamed = bc_df.rename(columns=renamed_columns)\n",
    "    bc_renamed = bc_renamed[renamed_columns.values()]\n",
    "\n",
    "    # Convert business cycle data to numeric, handling 'no data' entries\n",
    "    for col in bc_renamed.columns:\n",
    "        if col.startswith(('GDP_', 'CPI_')):\n",
    "            # Convert to numeric, coercing errors to NaN\n",
    "            bc_renamed[col] = pd.to_numeric(bc_renamed[col], errors='coerce')\n",
    "            # Divide by 100 only for valid numeric values\n",
    "            bc_renamed[col] = bc_renamed[col] / 100\n",
    "    \n",
    "    # Calculate excess returns (equity returns minus risk-free rate)\n",
    "    countries = ['US', 'UK', 'Japan', 'Hong Kong', 'Canada', 'Euro', 'Australia', 'New Zealand']\n",
    "    \n",
    "    # Remove Switzerland (CH) as it's not in interest rate data\n",
    "    if 'CH' in countries:\n",
    "        countries.remove('CH')\n",
    "    \n",
    "    # Calculate excess returns for each country\n",
    "    for country in countries:\n",
    "        equity_return = annual_df[f'Equity_{country}']\n",
    "        risk_free_rate = ir[f'Interest Rates_{country_to_abbr[country]}']\n",
    "        mf[f'Excess_Return_{country_to_abbr[country]}'] = equity_return - risk_free_rate\n",
    "    \n",
    "    # Add business cycle data (GDP and CPI)\n",
    "    mf = mf.join(bc_renamed, how='left')\n",
    "    \n",
    "    # Add currency returns\n",
    "    currency_cols = [col for col in annual_df.columns if col.startswith(\"Currency_\")]\n",
    "    mf = mf.join(annual_df[currency_cols], how='left')\n",
    "    \n",
    "    # Add monetary policy proxies (2-year bond yields)\n",
    "    monetary_policy_cols = [col for col in annual_df.columns \n",
    "                          if col.startswith(\"Bond Yield 2Y_\")]\n",
    "    mf = mf.join(annual_df[monetary_policy_cols], how='left')\n",
    "    \n",
    "    # Filter to desired time period (1980-2025)\n",
    "    mf = mf[(mf.index.year >= 1980) & (mf.index.year <= 2025)]\n",
    "    \n",
    "    return mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dd33d3c-5282-498e-827a-3ab778f18cf0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Equity_New Zealand'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/sts/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Equity_New Zealand'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m ar, ir \u001b[38;5;241m=\u001b[39m preprocess_asset_data(aqms_data)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Preprocess macro factors\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m mf \u001b[38;5;241m=\u001b[39m preprocess_macro_factors(bc_data, ar, ir)\n",
      "Cell \u001b[0;32mIn[2], line 268\u001b[0m, in \u001b[0;36mpreprocess_macro_factors\u001b[0;34m(bc_df, annual_df, ir)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# Calculate excess returns for each country\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m country \u001b[38;5;129;01min\u001b[39;00m countries:\n\u001b[0;32m--> 268\u001b[0m     equity_return \u001b[38;5;241m=\u001b[39m annual_df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEquity_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcountry\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    269\u001b[0m     risk_free_rate \u001b[38;5;241m=\u001b[39m ir[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInterest Rates_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcountry_to_abbr[country]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    270\u001b[0m     mf[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExcess_Return_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcountry_to_abbr[country]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m equity_return \u001b[38;5;241m-\u001b[39m risk_free_rate\n",
      "File \u001b[0;32m~/anaconda3/envs/sts/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/sts/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Equity_New Zealand'"
     ]
    }
   ],
   "source": [
    "data_dir = './'\n",
    "\n",
    "# Load and process data\n",
    "aqms_data = load_aqms_data(data_dir + 'AQMS.xlsx')\n",
    "bc_data = load_business_cycle_data(data_dir + 'Business Cycle.xls')\n",
    "\n",
    "# Preprocess asset data\n",
    "ar, ir = preprocess_asset_data(aqms_data)\n",
    "\n",
    "# Preprocess macro factors\n",
    "mf = preprocess_macro_factors(bc_data, ar, ir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "18a604ac-a02c-4e1a-a774-1ef0a4da21d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asset Returns columns sample:\n",
      "Index(['Equity_US', 'Equity_UK', 'Equity_JP', 'Equity_HK', 'Equity_CA',\n",
      "       'Equity_EU', 'Equity_CH', 'Equity_AU', 'Equity_NZ', 'Currency_UK',\n",
      "       'Currency_JP', 'Currency_EU', 'Currency_HK', 'Currency_CH',\n",
      "       'Currency_CA', 'Currency_AU', 'Currency_NZ', 'IR Future_SFRA Comdty',\n",
      "       'IR Future_SFR1YZ2 Comdty', 'IR Future_SFR1YZ3 Comdty',\n",
      "       'IR Future_SFR1YZ4 Comdty', 'IR Future_SFR1YZ5 Comdty',\n",
      "       'IR Future_SFR1YZ6 Comdty', 'IR Future_SFR2YZ2 Comdty',\n",
      "       'BondYield2Y_US', 'BondYield2Y_UK', 'BondYield2Y_JP', 'BondYield2Y_HK',\n",
      "       'BondYield2Y_CA', 'BondYield2Y_CH', 'BondYield2Y_AU', 'BondYield2Y_NZ',\n",
      "       'BondYield2Y_EU', 'BondYield10Y_US', 'BondYield10Y_UK',\n",
      "       'BondYield10Y_JP', 'BondYield10Y_HK', 'BondYield10Y_CA',\n",
      "       'BondYield10Y_CH', 'BondYield10Y_AU', 'BondYield10Y_NZ'],\n",
      "      dtype='object')\n",
      "\n",
      "Macro Factors columns sample:\n",
      "Index(['ExcessReturn_US', 'ExcessReturn_UK', 'ExcessReturn_JP',\n",
      "       'ExcessReturn_HK', 'ExcessReturn_CA', 'ExcessReturn_EU',\n",
      "       'ExcessReturn_AU', 'ExcessReturn_NZ', 'GDP_AU', 'GDP_CA', 'GDP_EU',\n",
      "       'GDP_HK', 'GDP_JP', 'GDP_NZ', 'GDP_CH', 'GDP_UK', 'GDP_US', 'CPI_AU',\n",
      "       'CPI_CA', 'CPI_EU', 'CPI_HK', 'CPI_JP', 'CPI_NZ', 'CPI_CH', 'CPI_UK',\n",
      "       'CPI_US', 'Currency_UK', 'Currency_JP', 'Currency_EU', 'Currency_HK',\n",
      "       'Currency_CH', 'Currency_CA', 'Currency_AU', 'Currency_NZ',\n",
      "       'BondYield2Y_US', 'BondYield2Y_UK', 'BondYield2Y_JP', 'BondYield2Y_HK',\n",
      "       'BondYield2Y_CA', 'BondYield2Y_CH', 'BondYield2Y_AU', 'BondYield2Y_NZ',\n",
      "       'BondYield2Y_EU'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Unify column names\n",
    "def standardize_column_names(df):\n",
    "    \"\"\"\n",
    "    Standardize column names to use consistent two-digit country abbreviations.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with columns to be renamed\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with standardized column names\n",
    "    \"\"\"\n",
    "    # Country name to two-letter abbreviation mapping\n",
    "    country_map = {\n",
    "        'US': 'US',\n",
    "        'UK': 'UK',\n",
    "        'Japan': 'JP',\n",
    "        'Hong Kong': 'HK',\n",
    "        'Canada': 'CA',\n",
    "        'Pan-Europe': 'EU',\n",
    "        'Euro': 'EU',\n",
    "        'Switzerland': 'CH',\n",
    "        'Australia': 'AU',\n",
    "        'New Zealand': 'NZ',\n",
    "        'GBP': 'UK',  # Currency special cases\n",
    "        'JPY': 'JP',\n",
    "        'EUR': 'EU',\n",
    "        'HKD': 'HK',\n",
    "        'CHF': 'CH',\n",
    "        'CAD': 'CA',\n",
    "        'AUD': 'AU',\n",
    "        'NZD': 'NZ'\n",
    "    }\n",
    "    \n",
    "    new_columns = []\n",
    "    for col in df.columns:\n",
    "        parts = col.split('_')\n",
    "        \n",
    "        # Handle different column patterns\n",
    "        if col.startswith('Equity_'):\n",
    "            country = parts[1]\n",
    "            new_col = f\"Equity_{country_map.get(country, country)}\"\n",
    "            \n",
    "        elif col.startswith('Currency_'):\n",
    "            currency = parts[1].split()[0]  # Get currency code before \"Curncy\"\n",
    "            new_col = f\"Currency_{country_map.get(currency, currency)}\"\n",
    "            \n",
    "        elif col.startswith('IR Future_'):\n",
    "            # Keep IR Future columns as-is (they're contracts, not countries)\n",
    "            new_col = col\n",
    "            \n",
    "        elif col.startswith(('Bond Yield 2Y_', 'Bond Yield 10Y_')):\n",
    "            # Extract country code from bond yield columns\n",
    "            bond_part = parts[1]\n",
    "            if bond_part.startswith('GT'):  # Handle GT-prefixed bonds (e.g., GTJPY)\n",
    "                country_code = bond_part[2:4]  # Gets JP from GTJPY\n",
    "            elif bond_part.startswith('GU'):  # Handle UK bonds (GUKG)\n",
    "                country_code = 'UK'\n",
    "            elif bond_part.startswith('US'):  # US bonds\n",
    "                country_code = 'US'\n",
    "            elif bond_part.startswith('HK'):  # Hong Kong bonds\n",
    "                country_code = 'HK'\n",
    "            else:\n",
    "                # Fallback - take first 2 characters\n",
    "                country_code = bond_part[:2]\n",
    "            new_col = f\"{parts[0].replace(' ','')}_{country_code}\"\n",
    "    \n",
    "        elif col.startswith('Excess_Return_'):\n",
    "            country = parts[2]  # Changed from parts[1] to parts[2]\n",
    "            new_col = f\"ExcessReturn_{country_map.get(country, country)}\"\n",
    "            \n",
    "        elif col.startswith(('GDP_', 'CPI_')):\n",
    "            country = parts[1]\n",
    "            new_col = f\"{parts[0]}_{country_map.get(country, country)}\"\n",
    "            \n",
    "        else:\n",
    "            new_col = col  # Leave unchanged if no pattern matches\n",
    "            \n",
    "        new_columns.append(new_col)\n",
    "    \n",
    "    # Apply the new column names\n",
    "    renamed_df = df.copy()\n",
    "    renamed_df.columns = new_columns\n",
    "    \n",
    "    return renamed_df\n",
    "\n",
    "\n",
    "# Apply to both DataFrames\n",
    "ar = standardize_column_names(ar)\n",
    "mf = standardize_column_names(mf)\n",
    "\n",
    "# Display sample results\n",
    "print(\"Asset Returns columns sample:\")\n",
    "print(ar.columns)  # First 10 columns\n",
    "\n",
    "print(\"\\nMacro Factors columns sample:\")\n",
    "print(mf.columns)  # First 10 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3523e8c-291c-43ae-bb02-15cc2d8730f5",
   "metadata": {},
   "source": [
    "One small manual: here main output is ar(asset return) and mf(macro factors).  \n",
    "\n",
    "ar: annualized geo mean return of each assets, imputed due to severe lack of interest rate future asset data  \n",
    "\n",
    "mf: annual return of macro factors\n",
    "\n",
    "all labels are encoded in column name, like \"Equity_JP\" or \"GDP_AU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ac483e1d-f5b1-4b80-a58a-12a78a50374a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after processing:\n",
      "['IRFutures_US', 'IRFutures_UK', 'IRFutures_JP', 'IRFutures_HK', 'IRFutures_CA', 'IRFutures_EU', 'IRFutures_CH', 'IRFutures_AU', 'IRFutures_NZ']\n",
      "\n",
      "Sample pseudo data:\n",
      "            IRFutures_US  IRFutures_JP\n",
      "Date                                  \n",
      "1970-12-31      0.011962     -0.016720\n",
      "1971-12-31      0.004961     -0.017224\n",
      "1972-12-31      0.005745     -0.007499\n",
      "1973-12-31      0.002636     -0.010859\n",
      "1974-12-31      0.007507     -0.003592\n"
     ]
    }
   ],
   "source": [
    "def process_ir_futures(ar_df):\n",
    "    \"\"\"\n",
    "    Process interest rate futures data by:\n",
    "    1. Dropping existing IR Future columns\n",
    "    2. Generating pseudo-data for each country\n",
    "    \n",
    "    Args:\n",
    "        ar_df (pd.DataFrame): Asset returns DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Processed DataFrame with pseudo IR Futures\n",
    "    \"\"\"\n",
    "    # 1. Drop all existing IR Future columns\n",
    "    ir_future_cols = [col for col in ar_df.columns if 'IR Future' in col]\n",
    "    ar_processed = ar_df.drop(columns=ir_future_cols)\n",
    "    \n",
    "    # 2. Generate pseudo-data for each country\n",
    "    countries = ['US', 'UK', 'JP', 'HK', 'CA', 'EU', 'CH', 'AU', 'NZ']\n",
    "    \n",
    "    for country in countries:\n",
    "        col_name = f'IRFutures_{country}'\n",
    "        \n",
    "        # Generate random returns between -0.02 and 0.02 (2%)\n",
    "        pseudo_data = np.random.uniform(low=-0.02, high=0.02, size=len(ar_df))\n",
    "        \n",
    "        # Add slight autocorrelation to make it more realistic\n",
    "        for i in range(1, len(pseudo_data)):\n",
    "            pseudo_data[i] = 0.7*pseudo_data[i-1] + 0.3*pseudo_data[i]\n",
    "        \n",
    "        ar_processed[col_name] = pseudo_data\n",
    "    \n",
    "    return ar_processed\n",
    "\n",
    "# Apply the processing\n",
    "ar = process_ir_futures(ar)\n",
    "\n",
    "# Verify the result\n",
    "print(\"Columns after processing:\")\n",
    "print([col for col in ar.columns if 'IRFutures' in col])\n",
    "print(\"\\nSample pseudo data:\")\n",
    "print(ar[[f'IRFutures_US', f'IRFutures_JP']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1796448c-c80e-4008-b397-13c878a769e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trade factor columns created:\n",
      "['TradeFactor_UK', 'TradeFactor_JP', 'TradeFactor_EU', 'TradeFactor_HK', 'TradeFactor_CH', 'TradeFactor_CA', 'TradeFactor_AU', 'TradeFactor_NZ', 'TradeFactor_US']\n",
      "\n",
      "Sample trade factors:\n",
      "TradeFactor_UK    46\n",
      "TradeFactor_JP    46\n",
      "TradeFactor_EU    46\n",
      "TradeFactor_HK    46\n",
      "TradeFactor_CH    46\n",
      "TradeFactor_CA    46\n",
      "TradeFactor_AU    46\n",
      "TradeFactor_NZ    46\n",
      "TradeFactor_US    46\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def transform_currency_returns(ar_df):\n",
    "    \"\"\"\n",
    "    Transform currency columns into asset returns in ar DataFrame.\n",
    "    Handles JPY special case (already USD/JPY) and converts others to USD-based returns.\n",
    "    \n",
    "    Args:\n",
    "        ar_df (pd.DataFrame): Asset returns DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Transformed DataFrame with currency returns\n",
    "    \"\"\"\n",
    "    # Currency columns to process (excluding JPY)\n",
    "    currency_cols = [col for col in ar_df.columns \n",
    "                   if col.startswith('Currency_') and not col.endswith('JP')]\n",
    "    \n",
    "    # JPY column (special handling)\n",
    "    jpy_col = [col for col in ar_df.columns if col.endswith('JP')][0]\n",
    "    \n",
    "    # Transform non-JPY currencies (currently USD/FCY → need FCY/USD)\n",
    "    for col in currency_cols:\n",
    "        # Convert from USD/FCY to FCY/USD and calculate returns\n",
    "        ar_df[col] = (1 / ar_df[col]).pct_change()\n",
    "    \n",
    "    # Transform JPY (currently USD/JPY → keep as is for returns)\n",
    "    ar_df[jpy_col] = ar_df[jpy_col].pct_change()\n",
    "    \n",
    "    # Rename columns to reflect they're now returns\n",
    "    ar_df.columns = [col.replace('Currency_', 'FXReturn_') for col in ar_df.columns]\n",
    "    \n",
    "    return ar_df\n",
    "\n",
    "\n",
    "def create_us_centric_trade_factors(mf_df):\n",
    "    \"\"\"\n",
    "    Create trade factors assuming each country primarily trades with the US.\n",
    "    For US, creates an equally-weighted basket of all other currencies.\n",
    "    \n",
    "    Args:\n",
    "        mf_df (pd.DataFrame): Macro factors DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with trade factors for all countries\n",
    "    \"\"\"\n",
    "    # Get all currency columns (USD per FCY)\n",
    "    currency_cols = [col for col in mf_df.columns if col.startswith('Currency_')]\n",
    "    countries = [col.split('_')[1] for col in currency_cols]\n",
    "    \n",
    "    # Create trade factors for each country\n",
    "    for country in countries + ['US']:  # Include US separately\n",
    "        if country == 'US':\n",
    "            # For US: equally-weighted basket of all other currencies\n",
    "            changes = []\n",
    "            for col in currency_cols:\n",
    "                other_country = col.split('_')[1]\n",
    "                if other_country == 'JP':\n",
    "                    changes.append(np.log(mf_df[col]).diff())  # JPY is USD/JPY\n",
    "                else:\n",
    "                    changes.append(np.log(1/mf_df[col]).diff())  # Others are FCY/USD\n",
    "            if changes:\n",
    "                mf_df[f'TradeFactor_US'] = pd.DataFrame(changes).mean()\n",
    "        else:\n",
    "            # For non-US countries: use their currency vs USD\n",
    "            col = f'Currency_{country}'\n",
    "            if country == 'JP':\n",
    "                mf_df[f'TradeFactor_{country}'] = np.log(mf_df[col]).diff()\n",
    "            else:\n",
    "                mf_df[f'TradeFactor_{country}'] = np.log(1/mf_df[col]).diff()\n",
    "    \n",
    "    # Apply 1-year smoothing\n",
    "    trade_cols = [col for col in mf_df.columns if col.startswith('TradeFactor_')]\n",
    "    mf_df[trade_cols] = mf_df[trade_cols].rolling(window=12).mean()\n",
    "    \n",
    "    return mf_df\n",
    "\n",
    "\n",
    "# Apply transformation on ar\n",
    "ar = transform_currency_returns(ar.copy())\n",
    "\n",
    "# Apply transformation on mf\n",
    "mf = create_us_centric_trade_factors(mf.copy())\n",
    "\n",
    "# Verify\n",
    "print(\"Trade factor columns created:\")\n",
    "print([col for col in mf.columns if col.startswith('TradeFactor_')])\n",
    "print(\"\\nSample trade factors:\")\n",
    "print(mf.filter(like='TradeFactor_').isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "3fe5c8e3-bbb6-4194-ae59-a01a0f567ff7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Equity_US', 'Equity_UK', 'Equity_JP', 'Equity_HK', 'Equity_CA',\n",
      "       'Equity_EU', 'Equity_CH', 'Equity_AU', 'Equity_NZ', 'FXReturn_UK',\n",
      "       'FXReturn_JP', 'FXReturn_EU', 'FXReturn_HK', 'FXReturn_CH',\n",
      "       'FXReturn_CA', 'FXReturn_AU', 'FXReturn_NZ', 'BondYield2Y_US',\n",
      "       'BondYield2Y_UK', 'BondYield2Y_JP', 'BondYield2Y_HK', 'BondYield2Y_CA',\n",
      "       'BondYield2Y_CH', 'BondYield2Y_AU', 'BondYield2Y_NZ', 'BondYield2Y_EU',\n",
      "       'BondYield10Y_US', 'BondYield10Y_UK', 'BondYield10Y_JP',\n",
      "       'BondYield10Y_HK', 'BondYield10Y_CA', 'BondYield10Y_CH',\n",
      "       'BondYield10Y_AU', 'BondYield10Y_NZ', 'IRFutures_US', 'IRFutures_UK',\n",
      "       'IRFutures_JP', 'IRFutures_HK', 'IRFutures_CA', 'IRFutures_EU',\n",
      "       'IRFutures_CH', 'IRFutures_AU', 'IRFutures_NZ'],\n",
      "      dtype='object')\n",
      "Index(['ExcessReturn_US', 'ExcessReturn_UK', 'ExcessReturn_JP',\n",
      "       'ExcessReturn_HK', 'ExcessReturn_CA', 'ExcessReturn_EU',\n",
      "       'ExcessReturn_AU', 'ExcessReturn_NZ', 'GDP_AU', 'GDP_CA', 'GDP_EU',\n",
      "       'GDP_HK', 'GDP_JP', 'GDP_NZ', 'GDP_CH', 'GDP_UK', 'GDP_US', 'CPI_AU',\n",
      "       'CPI_CA', 'CPI_EU', 'CPI_HK', 'CPI_JP', 'CPI_NZ', 'CPI_CH', 'CPI_UK',\n",
      "       'CPI_US', 'Currency_UK', 'Currency_JP', 'Currency_EU', 'Currency_HK',\n",
      "       'Currency_CH', 'Currency_CA', 'Currency_AU', 'Currency_NZ',\n",
      "       'BondYield2Y_US', 'BondYield2Y_UK', 'BondYield2Y_JP', 'BondYield2Y_HK',\n",
      "       'BondYield2Y_CA', 'BondYield2Y_CH', 'BondYield2Y_AU', 'BondYield2Y_NZ',\n",
      "       'BondYield2Y_EU', 'TradeFactor_UK', 'TradeFactor_JP', 'TradeFactor_EU',\n",
      "       'TradeFactor_HK', 'TradeFactor_CH', 'TradeFactor_CA', 'TradeFactor_AU',\n",
      "       'TradeFactor_NZ', 'TradeFactor_US'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(ar.columns)\n",
    "print(mf.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e009b3a-0f15-4e73-8235-4349a3a971e2",
   "metadata": {},
   "source": [
    "# 2. Contruct portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e68bafb-ddd4-4d93-9e92-78aa3d3ac05e",
   "metadata": {},
   "source": [
    "Business Cycle theme portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "122f9843-31f3-4f1d-8f22-c563b75c557a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business Cycle Portfolio Summary:\n",
      "Annualized Return: 2.98%\n",
      "Annualized Volatility: 102.18%\n",
      "\n",
      "Recent Weights:\n",
      "Date             2022-12-31  2023-12-31  2024-12-31  2025-12-31\n",
      "Equity_US         -0.088924    0.366426    0.019025   -0.016586\n",
      "Equity_UK          0.086629   -0.216447    0.025446    0.000976\n",
      "Equity_JP         -0.078598   -0.001704   -0.058026   -0.066343\n",
      "Equity_HK         -0.269641    0.565830    0.096076    0.059513\n",
      "Equity_CA          0.050486   -0.078398    0.001902   -0.022439\n",
      "Equity_EU         -0.047618   -0.431190    0.066112    0.041952\n",
      "Equity_CH          0.138263   -0.155092   -0.008799   -0.001951\n",
      "Equity_AU          0.148590   -0.124414   -0.064447    0.018537\n",
      "Equity_NZ          0.060813    0.074989   -0.077289   -0.013659\n",
      "FXReturn_UK        0.004391   -0.001226    0.000225   -0.000037\n",
      "FXReturn_JP       -0.005217    0.000317   -0.000450   -0.002280\n",
      "FXReturn_EU       -0.003415   -0.002769    0.000554    0.001329\n",
      "FXReturn_HK       -0.016326    0.004395    0.000797    0.001914\n",
      "FXReturn_CH        0.007394   -0.000785   -0.000052   -0.000134\n",
      "FXReturn_CA        0.002289   -0.000234    0.000035   -0.000817\n",
      "FXReturn_AU        0.007994   -0.000565   -0.000502    0.000549\n",
      "FXReturn_NZ        0.002890    0.000868   -0.000606   -0.000524\n",
      "BondYield2Y_US     9.279248   -4.748198   -2.700439    2.511001\n",
      "BondYield2Y_UK    -9.039784    2.804750   -3.611837   -0.147706\n",
      "BondYield2Y_JP     8.201658    0.022085    8.236339   10.044003\n",
      "BondYield2Y_HK    28.137075   -7.332102  -13.637218   -9.010061\n",
      "BondYield2Y_CA    -5.268218    1.015894   -0.270044    3.397236\n",
      "BondYield2Y_CH   -14.427734    2.009703    1.248953    0.295412\n",
      "BondYield2Y_AU   -15.505324    1.612179    9.147738   -2.806412\n",
      "BondYield2Y_NZ    -6.345808   -0.971724   10.970534    2.067883\n",
      "BondYield2Y_EU     4.968888    5.587415   -9.384026   -6.351355\n",
      "BondYield10Y_US    6.246180  -11.104972  -10.289954    3.273211\n",
      "BondYield10Y_UK   -5.311377    9.606142  -12.711120   -1.794986\n",
      "BondYield10Y_JP    5.566323    1.975731   18.764034   17.633102\n",
      "BondYield10Y_HK   18.143664  -18.190353  -39.343943  -18.688977\n",
      "BondYield10Y_CA   -2.931880    4.700878   -3.833512    4.962610\n",
      "BondYield10Y_CH   -8.710659    7.426024    0.201764   -0.950287\n",
      "BondYield10Y_AU   -9.390515    6.335966   21.185200   -6.863184\n",
      "BondYield10Y_NZ   -3.611736   -0.749415   26.027531    2.428511\n",
      "IRFutures_US       5.527712  -20.180521   -3.927364    4.513371\n",
      "IRFutures_UK      -5.385061   11.920587   -5.252849   -0.265492\n",
      "IRFutures_JP       4.885784    0.093863   11.978460   18.053484\n",
      "IRFutures_HK      16.761449  -31.162479  -19.833189  -16.195037\n",
      "IRFutures_CA      -3.138314    4.317693   -0.392736    6.106326\n",
      "IRFutures_EU       2.960001   23.747311  -13.647590  -11.416174\n",
      "IRFutures_CH      -8.594701    8.541523    1.816406    0.530985\n",
      "IRFutures_AU      -9.236628    6.851991   13.303946   -5.044356\n",
      "IRFutures_NZ      -3.780242   -4.129967   15.954917    3.716894\n"
     ]
    }
   ],
   "source": [
    "def standardize_weights(raw_weights):\n",
    "    \"\"\"\n",
    "    More robust weight standardization with debugging\n",
    "    \"\"\"\n",
    "    standardized = pd.DataFrame(index=raw_weights.index, columns=raw_weights.columns)\n",
    "    \n",
    "    for date, row in raw_weights.iterrows():\n",
    "        if row.isna().all():\n",
    "            continue\n",
    "            \n",
    "        # Calculate z-scores with minimum divisor\n",
    "        row_std = row.std()\n",
    "        divisor = row_std if row_std > 1e-8 else 1.0  # Prevent divide-by-zero\n",
    "        z_scores = (row - row.mean()) / divisor\n",
    "        \n",
    "        # Initialize weights\n",
    "        weights = pd.Series(0, index=z_scores.index)\n",
    "        \n",
    "        # Long positions (positive z-scores)\n",
    "        long_mask = z_scores > 0\n",
    "        if long_mask.any():\n",
    "            long_weights = z_scores[long_mask]\n",
    "            weights[long_mask] = long_weights / long_weights.sum()\n",
    "        \n",
    "        # Short positions (negative z-scores)\n",
    "        short_mask = z_scores < 0\n",
    "        if short_mask.any():\n",
    "            short_weights = z_scores[short_mask]\n",
    "            weights[short_mask] = short_weights / (-short_weights.sum())\n",
    "        \n",
    "        standardized.loc[date] = weights.values\n",
    "    \n",
    "    return standardized\n",
    "\n",
    "\n",
    "def calculate_bc_momentum(mf_df):\n",
    "    \"\"\"\n",
    "    Calculate Business Cycle momentum scores for each country using:\n",
    "    - 50% 1-year GDP growth change\n",
    "    - 50% 1-year CPI inflation change\n",
    "    \"\"\"\n",
    "    # Calculate 1-year changes for GDP and CPI\n",
    "    gdp_changes = mf_df.filter(like='GDP_').diff(12)\n",
    "    cpi_changes = mf_df.filter(like='CPI_').diff(12)\n",
    "    \n",
    "    # Combine 50/50 with proper sign conventions\n",
    "    bc_scores = {}\n",
    "    for country in [col.split('_')[1] for col in mf_df.columns if col.startswith('GDP_')]:\n",
    "        gdp_col = f'GDP_{country}'\n",
    "        cpi_col = f'CPI_{country}'\n",
    "        \n",
    "        # GDP: Higher growth = positive signal\n",
    "        gdp_signal = gdp_changes[gdp_col]\n",
    "        \n",
    "        # CPI: Higher inflation = negative signal (except for currencies)\n",
    "        cpi_signal = -cpi_changes[cpi_col]\n",
    "        \n",
    "        # Combine 50/50\n",
    "        bc_scores[country] = 0.5*gdp_signal + 0.5*cpi_signal\n",
    "    \n",
    "    return pd.DataFrame(bc_scores)\n",
    "\n",
    "\n",
    "def create_asset_class_portfolio(asset_returns, bc_scores, asset_class, target_vol=0.10):\n",
    "    \"\"\"\n",
    "    Modified version with correct weight standardization\n",
    "    \"\"\"\n",
    "    # Get relevant assets for this class\n",
    "    if asset_class == 'Equity':\n",
    "        assets = [col for col in asset_returns.columns if col.startswith('Equity_')]\n",
    "        countries = [col.split('_')[1] for col in assets]\n",
    "        # Equities: Long growth/inflation decline\n",
    "        raw_scores = bc_scores[countries]  # Get scores for relevant countries\n",
    "        \n",
    "    elif asset_class == 'FX':\n",
    "        assets = [col for col in asset_returns.columns if col.startswith('FXReturn_')]\n",
    "        countries = [col.split('_')[1] for col in assets]\n",
    "        # FX: Long growth/inflation increase (Balassa-Samuelson)\n",
    "        raw_scores = bc_scores[countries]\n",
    "        \n",
    "    elif asset_class in ['Bond2Y', 'Bond10Y', 'IRFutures']:\n",
    "        prefix = {\n",
    "            'Bond2Y': 'BondYield2Y_',\n",
    "            'Bond10Y': 'BondYield10Y_',\n",
    "            'IRFutures': 'IRFutures_'\n",
    "        }[asset_class]\n",
    "        assets = [col for col in asset_returns.columns if col.startswith(prefix)]\n",
    "        countries = [col.split('_')[-1] for col in assets]\n",
    "        # Fixed Income: Short growth/inflation increase\n",
    "        raw_scores = -bc_scores[countries]\n",
    "        \n",
    "    # Create DataFrame of raw scores aligned with asset returns index\n",
    "    raw_weights = pd.DataFrame(index=asset_returns.index, columns=assets)\n",
    "    for asset, country in zip(assets, countries):\n",
    "        raw_weights[asset] = raw_scores[country]\n",
    "    \n",
    "    # Standardize weights using row-wise z-scoring\n",
    "    weights = standardize_weights(raw_weights)\n",
    "    \n",
    "    if len(assets) > 1:\n",
    "        # Ensure we only use complete periods\n",
    "        valid_returns = asset_returns[assets].dropna()\n",
    "        \n",
    "        # Initialize portfolio variance\n",
    "        portfolio_variance = pd.Series(index=weights.index, dtype=float)\n",
    "        \n",
    "        for date in weights.index:\n",
    "            if date in valid_returns.index:\n",
    "                # Get current weights and filter to available assets\n",
    "                current_weights = weights.loc[date]\n",
    "                available_assets = current_weights.dropna().index\n",
    "                \n",
    "                if len(available_assets) > 0:\n",
    "                    # Get corresponding covariance matrix\n",
    "                    cov_matrix = valid_returns[available_assets].rolling(5).cov().loc[date]\n",
    "                    \n",
    "                    # Check dimension match\n",
    "                    if cov_matrix.shape[0] == len(available_assets):\n",
    "                        w = current_weights[available_assets].values.reshape(-1, 1)\n",
    "                        C = cov_matrix.values\n",
    "                        try:\n",
    "                            var = (w.T @ C @ w).item()\n",
    "                            portfolio_variance.loc[date] = var\n",
    "                        except ValueError:\n",
    "                            portfolio_variance.loc[date] = np.nan\n",
    "                    else:\n",
    "                        portfolio_variance.loc[date] = np.nan\n",
    "                else:\n",
    "                    portfolio_variance.loc[date] = np.nan\n",
    "            else:\n",
    "                portfolio_variance.loc[date] = np.nan\n",
    "        \n",
    "        # Calculate scaling factor\n",
    "        scaling_factor = target_vol / np.sqrt(portfolio_variance)\n",
    "        weights = weights.mul(scaling_factor, axis=0)\n",
    "    \n",
    "    return weights\n",
    "\n",
    "\n",
    "def construct_bc_portfolio(ar_df, mf_df):\n",
    "    \"\"\"\n",
    "    Construct complete Business Cycle long-short portfolio across all asset classes\n",
    "    \"\"\"\n",
    "    # Calculate BC momentum scores\n",
    "    bc_scores = calculate_bc_momentum(mf_df)\n",
    "    \n",
    "    # Create portfolios for each asset class\n",
    "    equity_weights = create_asset_class_portfolio(ar_df, bc_scores, 'Equity')\n",
    "    fx_weights = create_asset_class_portfolio(ar_df, bc_scores, 'FX')\n",
    "    bond2y_weights = create_asset_class_portfolio(ar_df, bc_scores, 'Bond2Y')\n",
    "    bond10y_weights = create_asset_class_portfolio(ar_df, bc_scores, 'Bond10Y')\n",
    "    ir_weights = create_asset_class_portfolio(ar_df, bc_scores, 'IRFutures')\n",
    "    \n",
    "    # Combine all weights\n",
    "    all_weights = pd.concat([\n",
    "        equity_weights,\n",
    "        fx_weights,\n",
    "        bond2y_weights,\n",
    "        bond10y_weights,\n",
    "        ir_weights\n",
    "    ], axis=1).fillna(0)\n",
    "    \n",
    "    # Calculate portfolio returns\n",
    "    portfolio_returns = (all_weights.shift(1) * ar_df[all_weights.columns]).sum(axis=1)\n",
    "    \n",
    "    return {\n",
    "        'weights': all_weights,\n",
    "        'returns': portfolio_returns,\n",
    "        'components': {\n",
    "            'Equity': equity_weights,\n",
    "            'FX': fx_weights,\n",
    "            'Bond2Y': bond2y_weights,\n",
    "            'Bond10Y': bond10y_weights,\n",
    "            'IRFutures': ir_weights\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Manage index\n",
    "ar = ar[(ar.index.year >= 1980) & (ar.index.year <= 2025)]\n",
    "\n",
    "# Construct the portfolio\n",
    "bc_portfolio = construct_bc_portfolio(ar, mf)\n",
    "\n",
    "# Example analysis\n",
    "print(\"Business Cycle Portfolio Summary:\")\n",
    "print(f\"Annualized Return: {bc_portfolio['returns'].mean():.2%}\")\n",
    "print(f\"Annualized Volatility: {bc_portfolio['returns'].std():.2%}\")\n",
    "print(\"\\nRecent Weights:\")\n",
    "print(bc_portfolio['weights'].iloc[-4:].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "5b81b868-dbc4-49ce-9a9a-1a762592dbbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "1980-12-31    0.000000\n",
       "1981-12-31    0.000000\n",
       "1982-12-31    0.000000\n",
       "1983-12-31    0.000000\n",
       "1984-12-31    0.000000\n",
       "1985-12-31    0.000000\n",
       "1986-12-31    0.000000\n",
       "1987-12-31    0.000000\n",
       "1988-12-31    0.000000\n",
       "1989-12-31    0.000000\n",
       "1990-12-31    0.000000\n",
       "1991-12-31    0.000000\n",
       "1992-12-31    0.000000\n",
       "1993-12-31   -0.435792\n",
       "1994-12-31   -0.770341\n",
       "1995-12-31   -1.037772\n",
       "1996-12-31    0.068143\n",
       "1997-12-31    1.043517\n",
       "1998-12-31   -1.783969\n",
       "1999-12-31   -0.105277\n",
       "2000-12-31   -1.406203\n",
       "2001-12-31   -1.110352\n",
       "2002-12-31   -0.341555\n",
       "2003-12-31   -0.533892\n",
       "2004-12-31   -0.526853\n",
       "2005-12-31    0.222189\n",
       "2006-12-31    1.899396\n",
       "2007-12-31    3.085659\n",
       "2008-12-31    0.304880\n",
       "2009-12-31    0.992267\n",
       "2010-12-31   -0.023659\n",
       "2011-12-31    1.623523\n",
       "2012-12-31    0.489915\n",
       "2013-12-31   -0.815976\n",
       "2014-12-31   -0.324709\n",
       "2015-12-31    0.069778\n",
       "2016-12-31    0.069975\n",
       "2017-12-31   -2.284321\n",
       "2018-12-31   -0.786516\n",
       "2019-12-31   -0.030101\n",
       "2020-12-31   -0.368038\n",
       "2021-12-31   -0.090778\n",
       "2022-12-31    0.545238\n",
       "2023-12-31    3.574559\n",
       "2024-12-31    0.148431\n",
       "2025-12-31    0.007488\n",
       "Freq: YE-DEC, dtype: float64"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc_portfolio['returns']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
